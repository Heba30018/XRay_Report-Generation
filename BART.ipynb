{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":951996,"sourceType":"datasetVersion","datasetId":516716}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import (\n    AutoFeatureExtractor, \n    AutoTokenizer, \n    VisionEncoderDecoderModel,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer, \n    default_data_collator,\n)\n\nfrom torch.utils.data import Dataset\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom pathlib import Path\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-01T06:33:51.130403Z","iopub.execute_input":"2024-03-01T06:33:51.131122Z","iopub.status.idle":"2024-03-01T06:33:58.695643Z","shell.execute_reply.started":"2024-03-01T06:33:51.131090Z","shell.execute_reply":"2024-03-01T06:33:58.694889Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-01 06:33:55.849951: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-01 06:33:55.850006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-01 06:33:55.851443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.read_csv('/kaggle/input/chest-xrays-indiana-university/indiana_projections.csv')\ndf1 = pd.read_csv('/kaggle/input/chest-xrays-indiana-university/indiana_reports.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:04.827825Z","iopub.execute_input":"2024-03-01T06:34:04.828885Z","iopub.status.idle":"2024-03-01T06:34:04.880013Z","shell.execute_reply.started":"2024-03-01T06:34:04.828850Z","shell.execute_reply":"2024-03-01T06:34:04.879173Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"images_captions_df = pd.DataFrame({'imgs': [],\n                                    'captions': []})\nfor i in range(len(df2)):\n    uid = df2.iloc[i]['uid']\n    image = df2.iloc[i]['filename']\n    index = df1.loc[df1['uid'] ==uid]\n    \n    if not index.empty:    \n        index = index.index[0]\n        caption = df1.iloc[index]['findings']\n        if type(caption) == float:\n         \n            continue \n        images_captions_df = pd.concat([images_captions_df, pd.DataFrame([{'imgs': image, 'captions': caption}])], ignore_index=True)\nimages_captions_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:05.153683Z","iopub.execute_input":"2024-03-01T06:34:05.154514Z","iopub.status.idle":"2024-03-01T06:34:12.763974Z","shell.execute_reply.started":"2024-03-01T06:34:05.154484Z","shell.execute_reply":"2024-03-01T06:34:12.763002Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                     imgs                                           captions\n0  1_IM-0001-4001.dcm.png  The cardiac silhouette and mediastinum size ar...\n1  1_IM-0001-3001.dcm.png  The cardiac silhouette and mediastinum size ar...\n2  2_IM-0652-1001.dcm.png  Borderline cardiomegaly. Midline sternotomy XX...\n3  2_IM-0652-2001.dcm.png  Borderline cardiomegaly. Midline sternotomy XX...\n4  4_IM-2050-1001.dcm.png  There are diffuse bilateral interstitial and a...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imgs</th>\n      <th>captions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_IM-0001-4001.dcm.png</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_IM-0001-3001.dcm.png</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_IM-0652-1001.dcm.png</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_IM-0652-2001.dcm.png</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4_IM-2050-1001.dcm.png</td>\n      <td>There are diffuse bilateral interstitial and a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"encoder_checkpoint = \"google/vit-base-patch16-224-in21k\"\ndecoder_checkpoint = \"ahmedabdo/facebook-bart-base-finetuned\"\n\nfeature_extractor = AutoFeatureExtractor.from_pretrained(encoder_checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(decoder_checkpoint)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:39.627095Z","iopub.execute_input":"2024-03-01T06:34:39.627827Z","iopub.status.idle":"2024-03-01T06:34:40.848372Z","shell.execute_reply.started":"2024-03-01T06:34:39.627795Z","shell.execute_reply":"2024-03-01T06:34:40.847217Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2280163e88994269ab5a90cdb2faa406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a587fdcf035f4215af77a485e7cf1416"}},"metadata":{}}]},{"cell_type":"code","source":"p = '/kaggle/input/chest-xrays-indiana-university/images/images_normalized/'\nimages_captions_df['imgs'] = p+ images_captions_df['imgs']\nimages_captions_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:33.131389Z","iopub.execute_input":"2024-03-01T06:34:33.132063Z","iopub.status.idle":"2024-03-01T06:34:33.143693Z","shell.execute_reply.started":"2024-03-01T06:34:33.132029Z","shell.execute_reply":"2024-03-01T06:34:33.142593Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                imgs  \\\n0  /kaggle/input/chest-xrays-indiana-university/i...   \n1  /kaggle/input/chest-xrays-indiana-university/i...   \n2  /kaggle/input/chest-xrays-indiana-university/i...   \n3  /kaggle/input/chest-xrays-indiana-university/i...   \n4  /kaggle/input/chest-xrays-indiana-university/i...   \n\n                                            captions  \n0  The cardiac silhouette and mediastinum size ar...  \n1  The cardiac silhouette and mediastinum size ar...  \n2  Borderline cardiomegaly. Midline sternotomy XX...  \n3  Borderline cardiomegaly. Midline sternotomy XX...  \n4  There are diffuse bilateral interstitial and a...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imgs</th>\n      <th>captions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>There are diffuse bilateral interstitial and a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# maximum length for the captions\nmax_length = 1024\nsample = images_captions_df.iloc[99]\n\n# sample image\nimage = Image.open(sample['imgs']).convert('RGB')\n# sample caption\ncaption = sample['captions']\n\n# apply feature extractor on the sample image\ninputs = feature_extractor(images=image, return_tensors='pt')\n# apply tokenizer\noutputs = tokenizer(\n            caption, \n            max_length=max_length, \n            \n            padding='max_length',\n            return_tensors='pt',\n        )\nprint(len(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:45.024225Z","iopub.execute_input":"2024-03-01T06:34:45.025138Z","iopub.status.idle":"2024-03-01T06:34:45.165349Z","shell.execute_reply.started":"2024-03-01T06:34:45.025096Z","shell.execute_reply":"2024-03-01T06:34:45.164365Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1024\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Inputs:\\n{inputs}\\nOutputs:\\n{outputs}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LoadDataset(Dataset):\n    def __init__(self, df):\n        self.images = images_captions_df['imgs'].values\n        self.captions = images_captions_df['captions'].values\n\n    \n    def __getitem__(self, idx):\n        # everything to return is stored inside this dict\n        inputs = dict()\n\n        # load the image and apply feature_extractor\n        image_path = str(self.images[idx])\n        image = Image.open(image_path).convert(\"RGB\")\n        image = feature_extractor(images=image, return_tensors='pt')\n\n        # load the caption and apply tokenizer\n        caption = self.captions[idx]\n        labels = tokenizer(\n            caption, \n            max_length=max_length, \n            truncation=True, \n            padding='max_length',\n            return_tensors='pt',\n        )['input_ids'][0]\n        \n        # store the inputs and labels in the dict we created\n        inputs['pixel_values'] = image['pixel_values'].squeeze()   \n        inputs['labels'] = labels\n        return inputs\n    \n    def __len__(self):\n        return len(self.images)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:49.325120Z","iopub.execute_input":"2024-03-01T06:34:49.325492Z","iopub.status.idle":"2024-03-01T06:34:49.334414Z","shell.execute_reply.started":"2024-03-01T06:34:49.325463Z","shell.execute_reply":"2024-03-01T06:34:49.333352Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_,test_df =train_test_split(images_captions_df, test_size=0.10, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:52.364412Z","iopub.execute_input":"2024-03-01T06:34:52.364806Z","iopub.status.idle":"2024-03-01T06:34:52.373181Z","shell.execute_reply.started":"2024-03-01T06:34:52.364773Z","shell.execute_reply":"2024-03-01T06:34:52.371924Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df,val_df =train_test_split(train_, test_size=0.10, shuffle=True, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:52.872605Z","iopub.execute_input":"2024-03-01T06:34:52.873606Z","iopub.status.idle":"2024-03-01T06:34:52.880524Z","shell.execute_reply.started":"2024-03-01T06:34:52.873570Z","shell.execute_reply":"2024-03-01T06:34:52.879574Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(len(train_df))\nprint(len(val_df))\nprint(len(test_df))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:53.924168Z","iopub.execute_input":"2024-03-01T06:34:53.925024Z","iopub.status.idle":"2024-03-01T06:34:53.929816Z","shell.execute_reply.started":"2024-03-01T06:34:53.924991Z","shell.execute_reply":"2024-03-01T06:34:53.928722Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"5239\n583\n647\n","output_type":"stream"}]},{"cell_type":"code","source":"train_ds = LoadDataset(train_df)\ntest_ds = LoadDataset(test_df)\nval_ds = LoadDataset(val_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:56.497846Z","iopub.execute_input":"2024-03-01T06:34:56.498734Z","iopub.status.idle":"2024-03-01T06:34:56.503585Z","shell.execute_reply.started":"2024-03-01T06:34:56.498696Z","shell.execute_reply":"2024-03-01T06:34:56.502503Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:34:56.795014Z","iopub.execute_input":"2024-03-01T06:34:56.795517Z","iopub.status.idle":"2024-03-01T06:34:56.806051Z","shell.execute_reply.started":"2024-03-01T06:34:56.795489Z","shell.execute_reply":"2024-03-01T06:34:56.804857Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                   imgs  \\\n2094  /kaggle/input/chest-xrays-indiana-university/i...   \n3658  /kaggle/input/chest-xrays-indiana-university/i...   \n4852  /kaggle/input/chest-xrays-indiana-university/i...   \n351   /kaggle/input/chest-xrays-indiana-university/i...   \n2166  /kaggle/input/chest-xrays-indiana-university/i...   \n\n                                               captions  \n2094  PA and lateral views the chest were obtained. ...  \n3658  Mild hypoventilation with bronchovascular crow...  \n4852  The lungs are clear bilaterally. Specifically,...  \n351   The heart is normal in size. The mediastinum i...  \n2166  No there is an dextroscoliosis of the thoracic...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imgs</th>\n      <th>captions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2094</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>PA and lateral views the chest were obtained. ...</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>Mild hypoventilation with bronchovascular crow...</td>\n    </tr>\n    <tr>\n      <th>4852</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>The lungs are clear bilaterally. Specifically,...</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>The heart is normal in size. The mediastinum i...</td>\n    </tr>\n    <tr>\n      <th>2166</th>\n      <td>/kaggle/input/chest-xrays-indiana-university/i...</td>\n      <td>No there is an dextroscoliosis of the thoracic...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"next(iter(test_ds))\n# next(iter(val_ds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_pretrained(\"ahmedabdo/facebook-bart-base-finetuned\").to('cuda')\nmodel.config.decoder_start_token_id = tokenizer.bos_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n# model.config.vocab_size = model.config.decoder.vocab_size\nmodel.config.num_beams = 4","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:37:04.176182Z","iopub.execute_input":"2024-03-01T06:37:04.176626Z","iopub.status.idle":"2024-03-01T06:37:09.037127Z","shell.execute_reply.started":"2024-03-01T06:37:04.176588Z","shell.execute_reply":"2024-03-01T06:37:09.035948Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(train_ds))\nmodel(pixel_values=batch['pixel_values'].unsqueeze(0), labels=batch['labels'].unsqueeze(0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"image-caption-generator\", \n    evaluation_strategy=\"epoch\", \n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,   \n    learning_rate=5e-5,\n    weight_decay=0.01,                  \n    num_train_epochs=2,          \n    save_strategy='epoch',               \n    report_to='wandb', \n     logging_dir=\"./logs\",\n    logging_steps=10,\n  \n)\n\ntrainer = Seq2SeqTrainer(\n    model=model, \n    tokenizer=feature_extractor, \n    data_collator=default_data_collator,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    args=training_args,\n    \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = 150\nimg =  Image.open(images_captions_df['imgs'][index]).convert(\"RGB\")\nfeatures = feature_extractor(img, return_tensors=\"pt\").pixel_values.to(\"cuda\")\ncaption = tokenizer.decode(model.generate(features,max_length = 2048)[0],skip_special_tokens=True)\nprint(\"predicted caption =====>\",caption)\nprint(\"actual caption =====> \", images_captions_df['captions'][index])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.push_to_hub(\"ahmedabdo/facebook-bart-base-finetuned\")\n# tokenizer.push_to_hub(\"ahmedabdo/facebook-bart-base-finetuned\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:35:28.673415Z","iopub.execute_input":"2024-03-01T06:35:28.674390Z","iopub.status.idle":"2024-03-01T06:35:49.305986Z","shell.execute_reply.started":"2024-03-01T06:35:28.674346Z","shell.execute_reply":"2024-03-01T06:35:49.304981Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'num_beams': 4}\nYour generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\nRemoved shared tensor {'decoder.lm_head.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/730M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c622fb8e7fc54131a832502604f35a7f"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ahmedabdo/facebook-bart-base-finetuned/commit/96c14af7374a3d133bfdd2cbe14ef81df0109352', commit_message='Upload model', commit_description='', oid='96c14af7374a3d133bfdd2cbe14ef81df0109352', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"import tqdm \npredicted_captions = [] \nfor i in tqdm.tqdm( val_df['imgs']):\n    img =  Image.open(i).convert(\"RGB\")\n    features = feature_extractor(img, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n    caption = tokenizer.decode(model.generate(features,max_length = 1024)[0],skip_special_tokens=True)\n    predicted_captions.append(caption)\nprint(len(predicted_captions))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:37:10.567977Z","iopub.execute_input":"2024-03-01T06:37:10.568696Z","iopub.status.idle":"2024-03-01T06:41:58.447341Z","shell.execute_reply.started":"2024-03-01T06:37:10.568630Z","shell.execute_reply":"2024-03-01T06:41:58.446386Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"  0%|          | 0/583 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1339: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n100%|██████████| 583/583 [04:47<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"583\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n\n# Assuming you have a list of predicted captions and a list of ground truth captions\ngenerated_captions = predicted_captions\nground_truth_captions = val_df['captions'].values\n# Convert the caption lists into the format expected by nltk\nground_truth_captions = [[caption.split() for caption in captions] for captions in ground_truth_captions]\ngenerated_captions = [caption.split() for caption in generated_captions]\n\n\n# Define the smoothing function to use\nsmoothie = SmoothingFunction().method4\n\n# Compute the BLEU score with smoothing\nweights = (0.25, 0.25, 0.25, 0.25)  # equal weights for 1-4 gram BLEU scores\nscore = corpus_bleu(ground_truth_captions, predicted_captions,weights =weights)\nprint(f'The BELU Score Is: {score}')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T06:44:26.487707Z","iopub.execute_input":"2024-03-01T06:44:26.488361Z","iopub.status.idle":"2024-03-01T06:44:59.819093Z","shell.execute_reply.started":"2024-03-01T06:44:26.488327Z","shell.execute_reply":"2024-03-01T06:44:59.818057Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"The BELU Score Is: 0.6084233073777816\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}